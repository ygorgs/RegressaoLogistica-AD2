---
title: "Regressão Logistíca - AD2"
author: "Ygor Santos"
date: "2 de maio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#bibliotecas usadas
require(dplyr)
require(ggplot2)
require(caret)
require(dplyr)
require(mlbench)
require(C50)
```

## Análise e Previsões da Votação do Impeachment

O objetivo dessa atividade é analisar os dados referentes aos deputados envolvidos na votação do impeachment da presidente Dilme e, a partir disso, tentar gerar um modelo que possa predizer o voto dos deputados baseados em algumas váriaveis que irei selecionar de acordo com sua relevância.

```{r read}

#leitura dos dados
dados <- read.csv2("~/ad2/Problema_5/data/deputados_temas_e_impeachment.csv", encoding="UTF-8")

```

## Análise Descritiva

```{r summary}

#sumario dos dados
summary(dados, na.rm=T)

```

Nos dados podemos encontrar os nomes dos deputados junto com seus respectivos partidos, estados e seus votos em diversos temas que são propostas que estavam/estão em votação na câmara:
  ------
  1 Cobrança de cursos em universidades públicas
  2 Tributação serviços de internet
  3 Terrorismo
  4 Infaticídio indígena
  5 Maioridade 1
  6 Maioridade 2
  7 Financiamento privado para partidos
  8 Financiamento privado para partidos e candidatos
  9 Terceirização
  10 Distritao
  11 Transgênico
  12 Reeleição
  13 Cota para mulheres legislativo
  14 Pensão
  15 Seguro Desemprego
  16 Tempo Mandato
  17 Voto Facultativo
  18 Voto impresso
  19 Coincidência reeleição

```{r informations}

#dimensões dos dados
dim(dados)

#tipos das variáveis
str(dados)

```

A amostra possui 540 observações e 25 váriaveis, sendo a variável IMPEACHMENT a minha variável resposta.

```{r plot1 }

qplot(dados$IMPEACHMENT, xlab = "Voto", ylab = "Quantidade")

```

## Previsões

Serão feitas previsões utilizando três modelos diferentes, são eles: Regressão Logistíca, KNN e Árvore de decisões. Ao final, os resultados obtidos nas previsões feitas por esses três modelos irão ser comparados afim de saber qual deles possuí o melhor desempenho na predição.

### Tratando Dados

Para melhorar os calculos para as previsões, serão considerados apenas os votos SIM e NÃO da coluna do IMPEACHMENT. As váriaveis que serão consideradas nos calculos são UF e partido.

```{r filter1}

dados <- filter(dados, grepl('SIM|NAO', dados$IMPEACHMENT)) %>% droplevels()

dados$IMPEACHMENT <- as.factor(dados$IMPEACHMENT)

```
### Divisão dos dados
A divisão da amostra de dados será feita de forma aleatória de modo que 75% dos dados sejam utilizados no treino e os 25% restantes serão usados no test.

```{r division}

#criando partições
split <- createDataPartition(y = dados$IMPEACHMENT, p = 0.75, list = F)
treino <- dados[split,]
teste <- dados[-split,]

#adicionando cabeçalho
names(treino) = names(dados)
names(teste) = names(dados)

```

### Regressão Logistíca

#### Treinando modelo

```{r logit, results=FALSE, warning=FALSE}

#treinando modelo
logistica <- train(IMPEACHMENT ~ UF + partido, method = 'glm', family = 'binomial', data=treino)

#sumario do modelo
summary(logistica)

```

#### Fazendo Previsões

```{r prediction1, warning=FALSE}

#realizando predições
predicoes_glm <- predict(logistica, teste)

confusionMatrix(teste$IMPEACHMENT, predicoes_glm)

```

###KNN

#### Treinando modelo

```{r knn, results=FALSE, warning=FALSE}

#treinando modelo
ctrl_knn <- trainControl(method = "repeatedcv", number = 10)
knnFit <- train(IMPEACHMENT ~ UF + partido, 
                data = treino, method="knn", 
                trControl = ctrl_knn, 
                preProcess = c("center","scale"), 
                tuneGrid = expand.grid(.k = 2:10),
                metric = "Accuracy")

#sumario do modelo
knnFit

```

#### Fazendo Previsões

```{r prediction2, warning=FALSE}

#realizando predições
predicoes_knn <- predict(knnFit, teste)

confusionMatrix(teste$IMPEACHMENT, predicoes_knn)

```

### Floresta

#### Treinando modelo

```{r tree, results=FALSE, warning=FALSE}

#configurando modelo
grid = expand.grid(.winnow = c(TRUE,FALSE),
                   .trials = c(1,5,10,20,30,40,50,60,70,80,90,100),
                   .model="tree")
ctrl_tree = trainControl(method = "repeatedcv", number = 10, repeats = 10,returnResamp = "all")

#treinando modelo
tree = train(IMPEACHMENT ~ UF + partido, 
             data = treino,
             tuneGrid = grid,
             trControl = ctrl_tree,
             method = "C5.0",
             verbose = FALSE,
             metric = "Accuracy")


#sumario do modelo
plot(tree)

```

#### Fazendo Previsões

```{r prediction3, results=FALSE, warning=FALSE}

#realizando predições
predicoes_tree <- predict(tree, teste)

confusionMatrix(teste$IMPEACHMENT, predicoes_tree)

```

## Conclusões

Dentre o três modelos analisados, o modelo de regressão logistíca e de árvores de decisões tiveram um desempenho melhor em relação ao KNN, ambos possuem uma acurácia elevada, embora o modelo de árvores seja um pouco mais preciso. O modelo de regressão logistica é bastante simples e por causa disso é menos custoso, o KNN e o modelo de árvores gastam mais tempo e mais recusos computacionais devido as diversas repetições que eles promovem para depois pegar o melhor resultado dessas repetições. 






